{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_ann_diabetes_hp.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2z1TmXvbyeT",
        "outputId": "692f1b0b-c726-4fa1-c9e8-25085f06590f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.activity.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fexperimentsandconfigs%20https%3a%2f%2fwww.googleapis.com%2fauth%2fphotos.native&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "4/1AY0e-g6c7PTC-UXz9X4t900q_A7_ovFMFQ5Pr1n_h_06xTudreKxuZpTYNM\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRbpAaUZbzlM"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/MyDrive/cuda/diabetes.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "gTOVqsA8cHOf",
        "outputId": "cf0edd4f-e737-4d68-f980-c7ad3612d8dd"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  ...  DiabetesPedigreeFunction  Age  Outcome\n",
              "0            6      148             72  ...                     0.627   50        1\n",
              "1            1       85             66  ...                     0.351   31        0\n",
              "2            8      183             64  ...                     0.672   32        1\n",
              "3            1       89             66  ...                     0.167   21        0\n",
              "4            0      137             40  ...                     2.288   33        1\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mqMXn70cIbZ",
        "outputId": "c0e53a05-c48e-4126-eadc-3277ca3e7e9a"
      },
      "source": [
        "!pip install torch"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.8.1+cu101)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BYZKImZcLZL",
        "outputId": "f11e2f66-362a-4f83-c3fb-66b2895b1e7d"
      },
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YQIdWfeches",
        "outputId": "858b0e21-7aac-41c9-92e7-6a9cc12ae87e"
      },
      "source": [
        "a = torch.rand(10000,10000)\n",
        "b = torch.rand(10000,10000)\n",
        "\n",
        "import time\n",
        "start = time.time()\n",
        "a.matmul(b)\n",
        "end = time.time()\n",
        "print(\"{} seconds\".format(end - start))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25.974895238876343 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leorjNi5cxI7",
        "outputId": "e14efcb6-80a6-4031-864d-7322813fbf81"
      },
      "source": [
        "a = a.cuda()\n",
        "b = b.cuda()\n",
        "\n",
        "start = time.time()\n",
        "a.matmul(b)\n",
        "end = time.time()\n",
        "print(\"{} seconds\".format(end - start))\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.011646747589111328 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXgmHmPIc5gf",
        "outputId": "059a47ee-5f54-4d05-f02c-3e1810855651"
      },
      "source": [
        "print(type(a),type(b))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOVN1eIec9wD"
      },
      "source": [
        "X = df.drop('Outcome',axis=1)\n",
        "y = df['Outcome']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train_scaled = sc.fit_transform(X_train)\n",
        "X_test_scaled = sc.transform(X_test)\n",
        "##### Creating Tensors\n",
        "X_train=torch.FloatTensor(X_train_scaled).cuda()\n",
        "X_test=torch.FloatTensor(X_test_scaled).cuda()\n",
        "y_train=torch.LongTensor(y_train.values).cuda()\n",
        "y_test=torch.LongTensor(y_test.values).cuda()\n",
        "\n"
      ],
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_PiojNGdG3F"
      },
      "source": [
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ANN_Model(nn.Module):\n",
        "    def __init__(self,input_features=8,hidden1=6,hidden2=4,out_features=2):\n",
        "        super().__init__()\n",
        "        self.f_connected1=nn.Sequential( nn.Linear(input_features,hidden1), nn.ReLU())\n",
        "        self.f_connected2=nn.Sequential( nn.Linear(hidden1,hidden2),nn.ReLU())\n",
        "        self.out=nn.Linear(hidden2,out_features)\n",
        "    def forward(self,x):\n",
        "        x=F.relu(self.f_connected1(x))\n",
        "        x=F.relu(self.f_connected2(x))\n",
        "        x=self.out(x)\n",
        "        return x"
      ],
      "execution_count": 301,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7QkLQ60dLyK",
        "outputId": "3621e9c4-4de1-41cc-aff6-bacf736a9ad1"
      },
      "source": [
        "####instantiate my ANN_model\n",
        "torch.manual_seed(20)\n",
        "model=ANN_Model()\n",
        "print(model)"
      ],
      "execution_count": 302,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ANN_Model(\n",
            "  (f_connected1): Sequential(\n",
            "    (0): Linear(in_features=8, out_features=6, bias=True)\n",
            "    (1): ReLU()\n",
            "  )\n",
            "  (f_connected2): Sequential(\n",
            "    (0): Linear(in_features=6, out_features=4, bias=True)\n",
            "    (1): ReLU()\n",
            "  )\n",
            "  (out): Linear(in_features=4, out_features=2, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMUX8YWWdR4a",
        "outputId": "416bda5a-44cd-4200-fa06-87a7866c7e1f"
      },
      "source": [
        "model.parameters"
      ],
      "execution_count": 277,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.parameters of ANN_Model(\n",
              "  (f_connected1): Sequential(\n",
              "    (0): Linear(in_features=8, out_features=6, bias=True)\n",
              "    (1): ReLU()\n",
              "  )\n",
              "  (f_connected2): Sequential(\n",
              "    (0): Linear(in_features=6, out_features=4, bias=True)\n",
              "    (1): ReLU()\n",
              "  )\n",
              "  (out): Linear(in_features=4, out_features=2, bias=True)\n",
              ")>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 277
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cE4EdxydZpW",
        "outputId": "8bc40dae-2f9e-4c49-db6c-7cf4a3714ac6"
      },
      "source": [
        "y_train.device"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVZSPqahdfoO",
        "outputId": "a430415b-fdff-4dcb-c7a5-26d39ec4e50c"
      },
      "source": [
        "for i in model.parameters():\n",
        "    print(i.is_cuda)"
      ],
      "execution_count": 303,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6xZLMu6evBu"
      },
      "source": [
        "model=model.cuda()"
      ],
      "execution_count": 304,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoGUrmw3feeL",
        "outputId": "d9c15cf2-c696-4465-89ad-d624c36ba131"
      },
      "source": [
        "model"
      ],
      "execution_count": 305,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ANN_Model(\n",
              "  (f_connected1): Sequential(\n",
              "    (0): Linear(in_features=8, out_features=6, bias=True)\n",
              "    (1): ReLU()\n",
              "  )\n",
              "  (f_connected2): Sequential(\n",
              "    (0): Linear(in_features=6, out_features=4, bias=True)\n",
              "    (1): ReLU()\n",
              "  )\n",
              "  (out): Linear(in_features=4, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 305
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYdayMMlffVG",
        "outputId": "28b5e508-693b-4661-bc1c-ad3dd065bd3e"
      },
      "source": [
        "for i in model.parameters():\n",
        "    print(i.is_cuda)"
      ],
      "execution_count": 306,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynJUsC8SfhJz"
      },
      "source": [
        "loss_function=nn.CrossEntropyLoss()\n",
        "optimizer=torch.optim.Adam(model.parameters(),lr=0.003)"
      ],
      "execution_count": 307,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g95iZJ9Rfn_M",
        "outputId": "126e9cb3-7d99-4e66-d84f-37f0cd4ad056"
      },
      "source": [
        "import time\n",
        "start_time=time.time()\n",
        "epochs=8000\n",
        "final_losses=[]\n",
        "for i in range(epochs):\n",
        "    i=i+1\n",
        "    y_pred=model.forward(X_train)\n",
        "    loss=loss_function(y_pred,y_train)\n",
        "    final_losses.append(loss)\n",
        "    if i%10==1:\n",
        "        print(\"Epoch number: {} and the loss : {}\".format(i,loss.item()))\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "print(time.time()-start_time)"
      ],
      "execution_count": 308,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch number: 1 and the loss : 0.6674039959907532\n",
            "Epoch number: 11 and the loss : 0.634199321269989\n",
            "Epoch number: 21 and the loss : 0.6050453782081604\n",
            "Epoch number: 31 and the loss : 0.5806847214698792\n",
            "Epoch number: 41 and the loss : 0.5587883591651917\n",
            "Epoch number: 51 and the loss : 0.5399642586708069\n",
            "Epoch number: 61 and the loss : 0.524530291557312\n",
            "Epoch number: 71 and the loss : 0.5115704536437988\n",
            "Epoch number: 81 and the loss : 0.5012460947036743\n",
            "Epoch number: 91 and the loss : 0.4928086996078491\n",
            "Epoch number: 101 and the loss : 0.4860762357711792\n",
            "Epoch number: 111 and the loss : 0.4804898202419281\n",
            "Epoch number: 121 and the loss : 0.47572827339172363\n",
            "Epoch number: 131 and the loss : 0.47161364555358887\n",
            "Epoch number: 141 and the loss : 0.4677991271018982\n",
            "Epoch number: 151 and the loss : 0.463825523853302\n",
            "Epoch number: 161 and the loss : 0.46017584204673767\n",
            "Epoch number: 171 and the loss : 0.45729392766952515\n",
            "Epoch number: 181 and the loss : 0.45453891158103943\n",
            "Epoch number: 191 and the loss : 0.4520505368709564\n",
            "Epoch number: 201 and the loss : 0.4499421715736389\n",
            "Epoch number: 211 and the loss : 0.44800907373428345\n",
            "Epoch number: 221 and the loss : 0.44617539644241333\n",
            "Epoch number: 231 and the loss : 0.4446222186088562\n",
            "Epoch number: 241 and the loss : 0.4431636929512024\n",
            "Epoch number: 251 and the loss : 0.44177865982055664\n",
            "Epoch number: 261 and the loss : 0.4404881000518799\n",
            "Epoch number: 271 and the loss : 0.43937891721725464\n",
            "Epoch number: 281 and the loss : 0.4383920729160309\n",
            "Epoch number: 291 and the loss : 0.43744200468063354\n",
            "Epoch number: 301 and the loss : 0.43646010756492615\n",
            "Epoch number: 311 and the loss : 0.4355221092700958\n",
            "Epoch number: 321 and the loss : 0.43427568674087524\n",
            "Epoch number: 331 and the loss : 0.43284687399864197\n",
            "Epoch number: 341 and the loss : 0.43163764476776123\n",
            "Epoch number: 351 and the loss : 0.43007180094718933\n",
            "Epoch number: 361 and the loss : 0.42829254269599915\n",
            "Epoch number: 371 and the loss : 0.42648082971572876\n",
            "Epoch number: 381 and the loss : 0.42496687173843384\n",
            "Epoch number: 391 and the loss : 0.4225192368030548\n",
            "Epoch number: 401 and the loss : 0.42034783959388733\n",
            "Epoch number: 411 and the loss : 0.41867250204086304\n",
            "Epoch number: 421 and the loss : 0.4174099266529083\n",
            "Epoch number: 431 and the loss : 0.41639676690101624\n",
            "Epoch number: 441 and the loss : 0.4154262840747833\n",
            "Epoch number: 451 and the loss : 0.4144272208213806\n",
            "Epoch number: 461 and the loss : 0.41363638639450073\n",
            "Epoch number: 471 and the loss : 0.4128803312778473\n",
            "Epoch number: 481 and the loss : 0.412026047706604\n",
            "Epoch number: 491 and the loss : 0.4112531542778015\n",
            "Epoch number: 501 and the loss : 0.410525381565094\n",
            "Epoch number: 511 and the loss : 0.4099973440170288\n",
            "Epoch number: 521 and the loss : 0.4095504581928253\n",
            "Epoch number: 531 and the loss : 0.4092087745666504\n",
            "Epoch number: 541 and the loss : 0.4088926613330841\n",
            "Epoch number: 551 and the loss : 0.4085460305213928\n",
            "Epoch number: 561 and the loss : 0.40823426842689514\n",
            "Epoch number: 571 and the loss : 0.4078530967235565\n",
            "Epoch number: 581 and the loss : 0.40755727887153625\n",
            "Epoch number: 591 and the loss : 0.4072650969028473\n",
            "Epoch number: 601 and the loss : 0.406915545463562\n",
            "Epoch number: 611 and the loss : 0.4066239297389984\n",
            "Epoch number: 621 and the loss : 0.4063059687614441\n",
            "Epoch number: 631 and the loss : 0.40585729479789734\n",
            "Epoch number: 641 and the loss : 0.4053443372249603\n",
            "Epoch number: 651 and the loss : 0.4050162136554718\n",
            "Epoch number: 661 and the loss : 0.4046791195869446\n",
            "Epoch number: 671 and the loss : 0.40436550974845886\n",
            "Epoch number: 681 and the loss : 0.40389925241470337\n",
            "Epoch number: 691 and the loss : 0.40352949500083923\n",
            "Epoch number: 701 and the loss : 0.40318381786346436\n",
            "Epoch number: 711 and the loss : 0.40255406498908997\n",
            "Epoch number: 721 and the loss : 0.4019666314125061\n",
            "Epoch number: 731 and the loss : 0.40166154503822327\n",
            "Epoch number: 741 and the loss : 0.4014037549495697\n",
            "Epoch number: 751 and the loss : 0.40122994780540466\n",
            "Epoch number: 761 and the loss : 0.40102753043174744\n",
            "Epoch number: 771 and the loss : 0.4006222188472748\n",
            "Epoch number: 781 and the loss : 0.39989399909973145\n",
            "Epoch number: 791 and the loss : 0.39933857321739197\n",
            "Epoch number: 801 and the loss : 0.3988409638404846\n",
            "Epoch number: 811 and the loss : 0.39847004413604736\n",
            "Epoch number: 821 and the loss : 0.3981270492076874\n",
            "Epoch number: 831 and the loss : 0.39789488911628723\n",
            "Epoch number: 841 and the loss : 0.3976130485534668\n",
            "Epoch number: 851 and the loss : 0.3973502218723297\n",
            "Epoch number: 861 and the loss : 0.39708447456359863\n",
            "Epoch number: 871 and the loss : 0.39671456813812256\n",
            "Epoch number: 881 and the loss : 0.39638420939445496\n",
            "Epoch number: 891 and the loss : 0.39607667922973633\n",
            "Epoch number: 901 and the loss : 0.3957741856575012\n",
            "Epoch number: 911 and the loss : 0.3953717350959778\n",
            "Epoch number: 921 and the loss : 0.3949500024318695\n",
            "Epoch number: 931 and the loss : 0.39456963539123535\n",
            "Epoch number: 941 and the loss : 0.39420729875564575\n",
            "Epoch number: 951 and the loss : 0.3938452899456024\n",
            "Epoch number: 961 and the loss : 0.3936048150062561\n",
            "Epoch number: 971 and the loss : 0.39326760172843933\n",
            "Epoch number: 981 and the loss : 0.3928588628768921\n",
            "Epoch number: 991 and the loss : 0.39241230487823486\n",
            "Epoch number: 1001 and the loss : 0.3919922709465027\n",
            "Epoch number: 1011 and the loss : 0.39180704951286316\n",
            "Epoch number: 1021 and the loss : 0.39161524176597595\n",
            "Epoch number: 1031 and the loss : 0.3914879560470581\n",
            "Epoch number: 1041 and the loss : 0.3913581371307373\n",
            "Epoch number: 1051 and the loss : 0.391254186630249\n",
            "Epoch number: 1061 and the loss : 0.3909599781036377\n",
            "Epoch number: 1071 and the loss : 0.390473335981369\n",
            "Epoch number: 1081 and the loss : 0.3898104131221771\n",
            "Epoch number: 1091 and the loss : 0.3894154727458954\n",
            "Epoch number: 1101 and the loss : 0.38916799426078796\n",
            "Epoch number: 1111 and the loss : 0.38896605372428894\n",
            "Epoch number: 1121 and the loss : 0.38878434896469116\n",
            "Epoch number: 1131 and the loss : 0.3886093497276306\n",
            "Epoch number: 1141 and the loss : 0.38847532868385315\n",
            "Epoch number: 1151 and the loss : 0.38833102583885193\n",
            "Epoch number: 1161 and the loss : 0.3881702721118927\n",
            "Epoch number: 1171 and the loss : 0.38803043961524963\n",
            "Epoch number: 1181 and the loss : 0.3879300057888031\n",
            "Epoch number: 1191 and the loss : 0.387773334980011\n",
            "Epoch number: 1201 and the loss : 0.3877050578594208\n",
            "Epoch number: 1211 and the loss : 0.3874818980693817\n",
            "Epoch number: 1221 and the loss : 0.3870167136192322\n",
            "Epoch number: 1231 and the loss : 0.3867224454879761\n",
            "Epoch number: 1241 and the loss : 0.3864619731903076\n",
            "Epoch number: 1251 and the loss : 0.3861633539199829\n",
            "Epoch number: 1261 and the loss : 0.3859468698501587\n",
            "Epoch number: 1271 and the loss : 0.38572970032691956\n",
            "Epoch number: 1281 and the loss : 0.38557854294776917\n",
            "Epoch number: 1291 and the loss : 0.385418564081192\n",
            "Epoch number: 1301 and the loss : 0.3846098482608795\n",
            "Epoch number: 1311 and the loss : 0.38436952233314514\n",
            "Epoch number: 1321 and the loss : 0.38405293226242065\n",
            "Epoch number: 1331 and the loss : 0.38386422395706177\n",
            "Epoch number: 1341 and the loss : 0.38365504145622253\n",
            "Epoch number: 1351 and the loss : 0.3834320604801178\n",
            "Epoch number: 1361 and the loss : 0.3832439184188843\n",
            "Epoch number: 1371 and the loss : 0.3830123245716095\n",
            "Epoch number: 1381 and the loss : 0.38282716274261475\n",
            "Epoch number: 1391 and the loss : 0.382607638835907\n",
            "Epoch number: 1401 and the loss : 0.38242775201797485\n",
            "Epoch number: 1411 and the loss : 0.3822859525680542\n",
            "Epoch number: 1421 and the loss : 0.3821522295475006\n",
            "Epoch number: 1431 and the loss : 0.38199660181999207\n",
            "Epoch number: 1441 and the loss : 0.38189899921417236\n",
            "Epoch number: 1451 and the loss : 0.38183531165122986\n",
            "Epoch number: 1461 and the loss : 0.38167187571525574\n",
            "Epoch number: 1471 and the loss : 0.38158223032951355\n",
            "Epoch number: 1481 and the loss : 0.3815380930900574\n",
            "Epoch number: 1491 and the loss : 0.3814605474472046\n",
            "Epoch number: 1501 and the loss : 0.381369411945343\n",
            "Epoch number: 1511 and the loss : 0.381241112947464\n",
            "Epoch number: 1521 and the loss : 0.3811891973018646\n",
            "Epoch number: 1531 and the loss : 0.38108953833580017\n",
            "Epoch number: 1541 and the loss : 0.38103529810905457\n",
            "Epoch number: 1551 and the loss : 0.3809327185153961\n",
            "Epoch number: 1561 and the loss : 0.3808760941028595\n",
            "Epoch number: 1571 and the loss : 0.3807898759841919\n",
            "Epoch number: 1581 and the loss : 0.3808039724826813\n",
            "Epoch number: 1591 and the loss : 0.3807339370250702\n",
            "Epoch number: 1601 and the loss : 0.3805880844593048\n",
            "Epoch number: 1611 and the loss : 0.3804928660392761\n",
            "Epoch number: 1621 and the loss : 0.3804306089878082\n",
            "Epoch number: 1631 and the loss : 0.38029831647872925\n",
            "Epoch number: 1641 and the loss : 0.380222886800766\n",
            "Epoch number: 1651 and the loss : 0.38019120693206787\n",
            "Epoch number: 1661 and the loss : 0.3800886869430542\n",
            "Epoch number: 1671 and the loss : 0.38001570105552673\n",
            "Epoch number: 1681 and the loss : 0.3800225257873535\n",
            "Epoch number: 1691 and the loss : 0.37988823652267456\n",
            "Epoch number: 1701 and the loss : 0.379818320274353\n",
            "Epoch number: 1711 and the loss : 0.37970396876335144\n",
            "Epoch number: 1721 and the loss : 0.37963029742240906\n",
            "Epoch number: 1731 and the loss : 0.3795115649700165\n",
            "Epoch number: 1741 and the loss : 0.3793810307979584\n",
            "Epoch number: 1751 and the loss : 0.37930628657341003\n",
            "Epoch number: 1761 and the loss : 0.3792290687561035\n",
            "Epoch number: 1771 and the loss : 0.37916842103004456\n",
            "Epoch number: 1781 and the loss : 0.37899160385131836\n",
            "Epoch number: 1791 and the loss : 0.3789723217487335\n",
            "Epoch number: 1801 and the loss : 0.3788616359233856\n",
            "Epoch number: 1811 and the loss : 0.3788074851036072\n",
            "Epoch number: 1821 and the loss : 0.37872225046157837\n",
            "Epoch number: 1831 and the loss : 0.3784831464290619\n",
            "Epoch number: 1841 and the loss : 0.37832725048065186\n",
            "Epoch number: 1851 and the loss : 0.378190279006958\n",
            "Epoch number: 1861 and the loss : 0.3780520260334015\n",
            "Epoch number: 1871 and the loss : 0.3779313862323761\n",
            "Epoch number: 1881 and the loss : 0.377808153629303\n",
            "Epoch number: 1891 and the loss : 0.3775286376476288\n",
            "Epoch number: 1901 and the loss : 0.3773452341556549\n",
            "Epoch number: 1911 and the loss : 0.37720879912376404\n",
            "Epoch number: 1921 and the loss : 0.3770686089992523\n",
            "Epoch number: 1931 and the loss : 0.3769680857658386\n",
            "Epoch number: 1941 and the loss : 0.37694811820983887\n",
            "Epoch number: 1951 and the loss : 0.3768862187862396\n",
            "Epoch number: 1961 and the loss : 0.3767809569835663\n",
            "Epoch number: 1971 and the loss : 0.3766998052597046\n",
            "Epoch number: 1981 and the loss : 0.3766988515853882\n",
            "Epoch number: 1991 and the loss : 0.37564435601234436\n",
            "Epoch number: 2001 and the loss : 0.37425950169563293\n",
            "Epoch number: 2011 and the loss : 0.3739469051361084\n",
            "Epoch number: 2021 and the loss : 0.3735399544239044\n",
            "Epoch number: 2031 and the loss : 0.3732515275478363\n",
            "Epoch number: 2041 and the loss : 0.373092383146286\n",
            "Epoch number: 2051 and the loss : 0.3729725182056427\n",
            "Epoch number: 2061 and the loss : 0.37292957305908203\n",
            "Epoch number: 2071 and the loss : 0.3728177547454834\n",
            "Epoch number: 2081 and the loss : 0.3727799654006958\n",
            "Epoch number: 2091 and the loss : 0.3727080523967743\n",
            "Epoch number: 2101 and the loss : 0.37263402342796326\n",
            "Epoch number: 2111 and the loss : 0.3725630044937134\n",
            "Epoch number: 2121 and the loss : 0.37256869673728943\n",
            "Epoch number: 2131 and the loss : 0.3724350929260254\n",
            "Epoch number: 2141 and the loss : 0.37236374616622925\n",
            "Epoch number: 2151 and the loss : 0.37240636348724365\n",
            "Epoch number: 2161 and the loss : 0.37236136198043823\n",
            "Epoch number: 2171 and the loss : 0.37230730056762695\n",
            "Epoch number: 2181 and the loss : 0.3722383379936218\n",
            "Epoch number: 2191 and the loss : 0.37220802903175354\n",
            "Epoch number: 2201 and the loss : 0.3721981644630432\n",
            "Epoch number: 2211 and the loss : 0.37209799885749817\n",
            "Epoch number: 2221 and the loss : 0.37209561467170715\n",
            "Epoch number: 2231 and the loss : 0.3720270097255707\n",
            "Epoch number: 2241 and the loss : 0.37198010087013245\n",
            "Epoch number: 2251 and the loss : 0.3719256818294525\n",
            "Epoch number: 2261 and the loss : 0.3719470202922821\n",
            "Epoch number: 2271 and the loss : 0.3718748986721039\n",
            "Epoch number: 2281 and the loss : 0.3718431293964386\n",
            "Epoch number: 2291 and the loss : 0.37180227041244507\n",
            "Epoch number: 2301 and the loss : 0.3717719614505768\n",
            "Epoch number: 2311 and the loss : 0.3718779683113098\n",
            "Epoch number: 2321 and the loss : 0.37169957160949707\n",
            "Epoch number: 2331 and the loss : 0.3716558516025543\n",
            "Epoch number: 2341 and the loss : 0.3716420829296112\n",
            "Epoch number: 2351 and the loss : 0.371653288602829\n",
            "Epoch number: 2361 and the loss : 0.37161317467689514\n",
            "Epoch number: 2371 and the loss : 0.3716120719909668\n",
            "Epoch number: 2381 and the loss : 0.3715374171733856\n",
            "Epoch number: 2391 and the loss : 0.3715001046657562\n",
            "Epoch number: 2401 and the loss : 0.3713470697402954\n",
            "Epoch number: 2411 and the loss : 0.37125784158706665\n",
            "Epoch number: 2421 and the loss : 0.3712214231491089\n",
            "Epoch number: 2431 and the loss : 0.37117186188697815\n",
            "Epoch number: 2441 and the loss : 0.37116408348083496\n",
            "Epoch number: 2451 and the loss : 0.37108492851257324\n",
            "Epoch number: 2461 and the loss : 0.3711370527744293\n",
            "Epoch number: 2471 and the loss : 0.3709914982318878\n",
            "Epoch number: 2481 and the loss : 0.3709588944911957\n",
            "Epoch number: 2491 and the loss : 0.37092477083206177\n",
            "Epoch number: 2501 and the loss : 0.37089720368385315\n",
            "Epoch number: 2511 and the loss : 0.3707996904850006\n",
            "Epoch number: 2521 and the loss : 0.3707641363143921\n",
            "Epoch number: 2531 and the loss : 0.3707806169986725\n",
            "Epoch number: 2541 and the loss : 0.37070006132125854\n",
            "Epoch number: 2551 and the loss : 0.37065547704696655\n",
            "Epoch number: 2561 and the loss : 0.3706530034542084\n",
            "Epoch number: 2571 and the loss : 0.3706510365009308\n",
            "Epoch number: 2581 and the loss : 0.3706127107143402\n",
            "Epoch number: 2591 and the loss : 0.37061238288879395\n",
            "Epoch number: 2601 and the loss : 0.3705286383628845\n",
            "Epoch number: 2611 and the loss : 0.3705562949180603\n",
            "Epoch number: 2621 and the loss : 0.37048330903053284\n",
            "Epoch number: 2631 and the loss : 0.3704860806465149\n",
            "Epoch number: 2641 and the loss : 0.37048760056495667\n",
            "Epoch number: 2651 and the loss : 0.3704899251461029\n",
            "Epoch number: 2661 and the loss : 0.3703978657722473\n",
            "Epoch number: 2671 and the loss : 0.3704574704170227\n",
            "Epoch number: 2681 and the loss : 0.3703928291797638\n",
            "Epoch number: 2691 and the loss : 0.3704042136669159\n",
            "Epoch number: 2701 and the loss : 0.37034961581230164\n",
            "Epoch number: 2711 and the loss : 0.37032365798950195\n",
            "Epoch number: 2721 and the loss : 0.37033283710479736\n",
            "Epoch number: 2731 and the loss : 0.37031739950180054\n",
            "Epoch number: 2741 and the loss : 0.37033382058143616\n",
            "Epoch number: 2751 and the loss : 0.37032341957092285\n",
            "Epoch number: 2761 and the loss : 0.37027812004089355\n",
            "Epoch number: 2771 and the loss : 0.37022316455841064\n",
            "Epoch number: 2781 and the loss : 0.3701861798763275\n",
            "Epoch number: 2791 and the loss : 0.3702211380004883\n",
            "Epoch number: 2801 and the loss : 0.3701838552951813\n",
            "Epoch number: 2811 and the loss : 0.3701615333557129\n",
            "Epoch number: 2821 and the loss : 0.3702249228954315\n",
            "Epoch number: 2831 and the loss : 0.37014102935791016\n",
            "Epoch number: 2841 and the loss : 0.37021884322166443\n",
            "Epoch number: 2851 and the loss : 0.37022724747657776\n",
            "Epoch number: 2861 and the loss : 0.3701498806476593\n",
            "Epoch number: 2871 and the loss : 0.3701419532299042\n",
            "Epoch number: 2881 and the loss : 0.3701052963733673\n",
            "Epoch number: 2891 and the loss : 0.37013939023017883\n",
            "Epoch number: 2901 and the loss : 0.3701383173465729\n",
            "Epoch number: 2911 and the loss : 0.3701281249523163\n",
            "Epoch number: 2921 and the loss : 0.37007471919059753\n",
            "Epoch number: 2931 and the loss : 0.3700549900531769\n",
            "Epoch number: 2941 and the loss : 0.3700219988822937\n",
            "Epoch number: 2951 and the loss : 0.370063453912735\n",
            "Epoch number: 2961 and the loss : 0.370038241147995\n",
            "Epoch number: 2971 and the loss : 0.3700188100337982\n",
            "Epoch number: 2981 and the loss : 0.3700021505355835\n",
            "Epoch number: 2991 and the loss : 0.37009021639823914\n",
            "Epoch number: 3001 and the loss : 0.3700217604637146\n",
            "Epoch number: 3011 and the loss : 0.3699807822704315\n",
            "Epoch number: 3021 and the loss : 0.369886189699173\n",
            "Epoch number: 3031 and the loss : 0.3695974051952362\n",
            "Epoch number: 3041 and the loss : 0.369598925113678\n",
            "Epoch number: 3051 and the loss : 0.3695511817932129\n",
            "Epoch number: 3061 and the loss : 0.3695215880870819\n",
            "Epoch number: 3071 and the loss : 0.36949989199638367\n",
            "Epoch number: 3081 and the loss : 0.36952707171440125\n",
            "Epoch number: 3091 and the loss : 0.3694959282875061\n",
            "Epoch number: 3101 and the loss : 0.3695986270904541\n",
            "Epoch number: 3111 and the loss : 0.36947181820869446\n",
            "Epoch number: 3121 and the loss : 0.369395911693573\n",
            "Epoch number: 3131 and the loss : 0.3693716824054718\n",
            "Epoch number: 3141 and the loss : 0.3693808913230896\n",
            "Epoch number: 3151 and the loss : 0.3693965971469879\n",
            "Epoch number: 3161 and the loss : 0.36929911375045776\n",
            "Epoch number: 3171 and the loss : 0.36927980184555054\n",
            "Epoch number: 3181 and the loss : 0.3692454993724823\n",
            "Epoch number: 3191 and the loss : 0.36908718943595886\n",
            "Epoch number: 3201 and the loss : 0.36904484033584595\n",
            "Epoch number: 3211 and the loss : 0.36896464228630066\n",
            "Epoch number: 3221 and the loss : 0.36906275153160095\n",
            "Epoch number: 3231 and the loss : 0.3689921796321869\n",
            "Epoch number: 3241 and the loss : 0.36893337965011597\n",
            "Epoch number: 3251 and the loss : 0.36886948347091675\n",
            "Epoch number: 3261 and the loss : 0.36898064613342285\n",
            "Epoch number: 3271 and the loss : 0.3688913583755493\n",
            "Epoch number: 3281 and the loss : 0.3688688576221466\n",
            "Epoch number: 3291 and the loss : 0.3688372075557709\n",
            "Epoch number: 3301 and the loss : 0.3688255846500397\n",
            "Epoch number: 3311 and the loss : 0.3687894940376282\n",
            "Epoch number: 3321 and the loss : 0.36871835589408875\n",
            "Epoch number: 3331 and the loss : 0.36855804920196533\n",
            "Epoch number: 3341 and the loss : 0.3684667646884918\n",
            "Epoch number: 3351 and the loss : 0.368478924036026\n",
            "Epoch number: 3361 and the loss : 0.3684239983558655\n",
            "Epoch number: 3371 and the loss : 0.36841756105422974\n",
            "Epoch number: 3381 and the loss : 0.36843323707580566\n",
            "Epoch number: 3391 and the loss : 0.36837807297706604\n",
            "Epoch number: 3401 and the loss : 0.3684350848197937\n",
            "Epoch number: 3411 and the loss : 0.3683765232563019\n",
            "Epoch number: 3421 and the loss : 0.36839210987091064\n",
            "Epoch number: 3431 and the loss : 0.3683708906173706\n",
            "Epoch number: 3441 and the loss : 0.36834439635276794\n",
            "Epoch number: 3451 and the loss : 0.3683515787124634\n",
            "Epoch number: 3461 and the loss : 0.3683464825153351\n",
            "Epoch number: 3471 and the loss : 0.36828964948654175\n",
            "Epoch number: 3481 and the loss : 0.36829161643981934\n",
            "Epoch number: 3491 and the loss : 0.3684026002883911\n",
            "Epoch number: 3501 and the loss : 0.3682563006877899\n",
            "Epoch number: 3511 and the loss : 0.3682672679424286\n",
            "Epoch number: 3521 and the loss : 0.3682369887828827\n",
            "Epoch number: 3531 and the loss : 0.36835700273513794\n",
            "Epoch number: 3541 and the loss : 0.36837950348854065\n",
            "Epoch number: 3551 and the loss : 0.3682510256767273\n",
            "Epoch number: 3561 and the loss : 0.3682387173175812\n",
            "Epoch number: 3571 and the loss : 0.36825472116470337\n",
            "Epoch number: 3581 and the loss : 0.3681568205356598\n",
            "Epoch number: 3591 and the loss : 0.36821454763412476\n",
            "Epoch number: 3601 and the loss : 0.36813271045684814\n",
            "Epoch number: 3611 and the loss : 0.3682452142238617\n",
            "Epoch number: 3621 and the loss : 0.36820483207702637\n",
            "Epoch number: 3631 and the loss : 0.36813387274742126\n",
            "Epoch number: 3641 and the loss : 0.3681752383708954\n",
            "Epoch number: 3651 and the loss : 0.3681212067604065\n",
            "Epoch number: 3661 and the loss : 0.36812824010849\n",
            "Epoch number: 3671 and the loss : 0.36825501918792725\n",
            "Epoch number: 3681 and the loss : 0.36813682317733765\n",
            "Epoch number: 3691 and the loss : 0.36808714270591736\n",
            "Epoch number: 3701 and the loss : 0.36809128522872925\n",
            "Epoch number: 3711 and the loss : 0.3682556450366974\n",
            "Epoch number: 3721 and the loss : 0.36812978982925415\n",
            "Epoch number: 3731 and the loss : 0.368103563785553\n",
            "Epoch number: 3741 and the loss : 0.3680781424045563\n",
            "Epoch number: 3751 and the loss : 0.3680693209171295\n",
            "Epoch number: 3761 and the loss : 0.3680945932865143\n",
            "Epoch number: 3771 and the loss : 0.36807408928871155\n",
            "Epoch number: 3781 and the loss : 0.368030846118927\n",
            "Epoch number: 3791 and the loss : 0.3680609464645386\n",
            "Epoch number: 3801 and the loss : 0.36801978945732117\n",
            "Epoch number: 3811 and the loss : 0.3680698871612549\n",
            "Epoch number: 3821 and the loss : 0.36808955669403076\n",
            "Epoch number: 3831 and the loss : 0.36805400252342224\n",
            "Epoch number: 3841 and the loss : 0.3680970370769501\n",
            "Epoch number: 3851 and the loss : 0.3680141270160675\n",
            "Epoch number: 3861 and the loss : 0.36801204085350037\n",
            "Epoch number: 3871 and the loss : 0.3679932653903961\n",
            "Epoch number: 3881 and the loss : 0.3679806590080261\n",
            "Epoch number: 3891 and the loss : 0.36798095703125\n",
            "Epoch number: 3901 and the loss : 0.3679664134979248\n",
            "Epoch number: 3911 and the loss : 0.36797717213630676\n",
            "Epoch number: 3921 and the loss : 0.3680002987384796\n",
            "Epoch number: 3931 and the loss : 0.36796027421951294\n",
            "Epoch number: 3941 and the loss : 0.36796653270721436\n",
            "Epoch number: 3951 and the loss : 0.3679947555065155\n",
            "Epoch number: 3961 and the loss : 0.3679882884025574\n",
            "Epoch number: 3971 and the loss : 0.3679710030555725\n",
            "Epoch number: 3981 and the loss : 0.3679410219192505\n",
            "Epoch number: 3991 and the loss : 0.3679315745830536\n",
            "Epoch number: 4001 and the loss : 0.36793631315231323\n",
            "Epoch number: 4011 and the loss : 0.3679162263870239\n",
            "Epoch number: 4021 and the loss : 0.36793777346611023\n",
            "Epoch number: 4031 and the loss : 0.36793914437294006\n",
            "Epoch number: 4041 and the loss : 0.3679247796535492\n",
            "Epoch number: 4051 and the loss : 0.36791539192199707\n",
            "Epoch number: 4061 and the loss : 0.36802712082862854\n",
            "Epoch number: 4071 and the loss : 0.3679868280887604\n",
            "Epoch number: 4081 and the loss : 0.3679966330528259\n",
            "Epoch number: 4091 and the loss : 0.3679036796092987\n",
            "Epoch number: 4101 and the loss : 0.3678925335407257\n",
            "Epoch number: 4111 and the loss : 0.3679051399230957\n",
            "Epoch number: 4121 and the loss : 0.3678949177265167\n",
            "Epoch number: 4131 and the loss : 0.3678739666938782\n",
            "Epoch number: 4141 and the loss : 0.36784565448760986\n",
            "Epoch number: 4151 and the loss : 0.36785537004470825\n",
            "Epoch number: 4161 and the loss : 0.36787325143814087\n",
            "Epoch number: 4171 and the loss : 0.36789605021476746\n",
            "Epoch number: 4181 and the loss : 0.3678324818611145\n",
            "Epoch number: 4191 and the loss : 0.3677777051925659\n",
            "Epoch number: 4201 and the loss : 0.3678100109100342\n",
            "Epoch number: 4211 and the loss : 0.36781662702560425\n",
            "Epoch number: 4221 and the loss : 0.36781445145606995\n",
            "Epoch number: 4231 and the loss : 0.36777427792549133\n",
            "Epoch number: 4241 and the loss : 0.3677748441696167\n",
            "Epoch number: 4251 and the loss : 0.3678628206253052\n",
            "Epoch number: 4261 and the loss : 0.36790362000465393\n",
            "Epoch number: 4271 and the loss : 0.36788153648376465\n",
            "Epoch number: 4281 and the loss : 0.36780670285224915\n",
            "Epoch number: 4291 and the loss : 0.36776697635650635\n",
            "Epoch number: 4301 and the loss : 0.3679956793785095\n",
            "Epoch number: 4311 and the loss : 0.36784827709198\n",
            "Epoch number: 4321 and the loss : 0.3678290545940399\n",
            "Epoch number: 4331 and the loss : 0.3677956461906433\n",
            "Epoch number: 4341 and the loss : 0.3677888512611389\n",
            "Epoch number: 4351 and the loss : 0.36783087253570557\n",
            "Epoch number: 4361 and the loss : 0.3678828775882721\n",
            "Epoch number: 4371 and the loss : 0.3677370548248291\n",
            "Epoch number: 4381 and the loss : 0.36778292059898376\n",
            "Epoch number: 4391 and the loss : 0.36772459745407104\n",
            "Epoch number: 4401 and the loss : 0.3678145408630371\n",
            "Epoch number: 4411 and the loss : 0.36773255467414856\n",
            "Epoch number: 4421 and the loss : 0.36774110794067383\n",
            "Epoch number: 4431 and the loss : 0.3676929175853729\n",
            "Epoch number: 4441 and the loss : 0.3676813840866089\n",
            "Epoch number: 4451 and the loss : 0.3676700294017792\n",
            "Epoch number: 4461 and the loss : 0.3677442669868469\n",
            "Epoch number: 4471 and the loss : 0.36769333481788635\n",
            "Epoch number: 4481 and the loss : 0.3676999509334564\n",
            "Epoch number: 4491 and the loss : 0.36769142746925354\n",
            "Epoch number: 4501 and the loss : 0.36765256524086\n",
            "Epoch number: 4511 and the loss : 0.36762723326683044\n",
            "Epoch number: 4521 and the loss : 0.36764106154441833\n",
            "Epoch number: 4531 and the loss : 0.3676178455352783\n",
            "Epoch number: 4541 and the loss : 0.36761587858200073\n",
            "Epoch number: 4551 and the loss : 0.36762163043022156\n",
            "Epoch number: 4561 and the loss : 0.3677103817462921\n",
            "Epoch number: 4571 and the loss : 0.3677854835987091\n",
            "Epoch number: 4581 and the loss : 0.3676510155200958\n",
            "Epoch number: 4591 and the loss : 0.36783215403556824\n",
            "Epoch number: 4601 and the loss : 0.3676462471485138\n",
            "Epoch number: 4611 and the loss : 0.36764636635780334\n",
            "Epoch number: 4621 and the loss : 0.3676314949989319\n",
            "Epoch number: 4631 and the loss : 0.36756548285484314\n",
            "Epoch number: 4641 and the loss : 0.3675842583179474\n",
            "Epoch number: 4651 and the loss : 0.36754897236824036\n",
            "Epoch number: 4661 and the loss : 0.3676493465900421\n",
            "Epoch number: 4671 and the loss : 0.3676212728023529\n",
            "Epoch number: 4681 and the loss : 0.36753758788108826\n",
            "Epoch number: 4691 and the loss : 0.3675519824028015\n",
            "Epoch number: 4701 and the loss : 0.36757877469062805\n",
            "Epoch number: 4711 and the loss : 0.3675202429294586\n",
            "Epoch number: 4721 and the loss : 0.36749666929244995\n",
            "Epoch number: 4731 and the loss : 0.3674852252006531\n",
            "Epoch number: 4741 and the loss : 0.3676023781299591\n",
            "Epoch number: 4751 and the loss : 0.3676510155200958\n",
            "Epoch number: 4761 and the loss : 0.3675216734409332\n",
            "Epoch number: 4771 and the loss : 0.36746639013290405\n",
            "Epoch number: 4781 and the loss : 0.36747342348098755\n",
            "Epoch number: 4791 and the loss : 0.3674905300140381\n",
            "Epoch number: 4801 and the loss : 0.3674948513507843\n",
            "Epoch number: 4811 and the loss : 0.36751753091812134\n",
            "Epoch number: 4821 and the loss : 0.36751002073287964\n",
            "Epoch number: 4831 and the loss : 0.36747294664382935\n",
            "Epoch number: 4841 and the loss : 0.3675483763217926\n",
            "Epoch number: 4851 and the loss : 0.36745911836624146\n",
            "Epoch number: 4861 and the loss : 0.3674314022064209\n",
            "Epoch number: 4871 and the loss : 0.3674483597278595\n",
            "Epoch number: 4881 and the loss : 0.36744093894958496\n",
            "Epoch number: 4891 and the loss : 0.36753374338150024\n",
            "Epoch number: 4901 and the loss : 0.367574542760849\n",
            "Epoch number: 4911 and the loss : 0.3675292134284973\n",
            "Epoch number: 4921 and the loss : 0.36741796135902405\n",
            "Epoch number: 4931 and the loss : 0.3675302267074585\n",
            "Epoch number: 4941 and the loss : 0.3675120770931244\n",
            "Epoch number: 4951 and the loss : 0.3674110770225525\n",
            "Epoch number: 4961 and the loss : 0.36743998527526855\n",
            "Epoch number: 4971 and the loss : 0.367428183555603\n",
            "Epoch number: 4981 and the loss : 0.3673458397388458\n",
            "Epoch number: 4991 and the loss : 0.3673493564128876\n",
            "Epoch number: 5001 and the loss : 0.36741796135902405\n",
            "Epoch number: 5011 and the loss : 0.3674863576889038\n",
            "Epoch number: 5021 and the loss : 0.367272287607193\n",
            "Epoch number: 5031 and the loss : 0.3672471046447754\n",
            "Epoch number: 5041 and the loss : 0.3673543334007263\n",
            "Epoch number: 5051 and the loss : 0.3672928512096405\n",
            "Epoch number: 5061 and the loss : 0.3673784136772156\n",
            "Epoch number: 5071 and the loss : 0.36736005544662476\n",
            "Epoch number: 5081 and the loss : 0.36729785799980164\n",
            "Epoch number: 5091 and the loss : 0.3673727512359619\n",
            "Epoch number: 5101 and the loss : 0.367392361164093\n",
            "Epoch number: 5111 and the loss : 0.36734989285469055\n",
            "Epoch number: 5121 and the loss : 0.3674979507923126\n",
            "Epoch number: 5131 and the loss : 0.3673762083053589\n",
            "Epoch number: 5141 and the loss : 0.3674599528312683\n",
            "Epoch number: 5151 and the loss : 0.367267370223999\n",
            "Epoch number: 5161 and the loss : 0.3672037124633789\n",
            "Epoch number: 5171 and the loss : 0.36719566583633423\n",
            "Epoch number: 5181 and the loss : 0.36721929907798767\n",
            "Epoch number: 5191 and the loss : 0.36720961332321167\n",
            "Epoch number: 5201 and the loss : 0.36719560623168945\n",
            "Epoch number: 5211 and the loss : 0.36720484495162964\n",
            "Epoch number: 5221 and the loss : 0.36730560660362244\n",
            "Epoch number: 5231 and the loss : 0.3674999475479126\n",
            "Epoch number: 5241 and the loss : 0.3672071397304535\n",
            "Epoch number: 5251 and the loss : 0.3673642873764038\n",
            "Epoch number: 5261 and the loss : 0.36727702617645264\n",
            "Epoch number: 5271 and the loss : 0.36718520522117615\n",
            "Epoch number: 5281 and the loss : 0.3672938346862793\n",
            "Epoch number: 5291 and the loss : 0.36714133620262146\n",
            "Epoch number: 5301 and the loss : 0.36713892221450806\n",
            "Epoch number: 5311 and the loss : 0.367146372795105\n",
            "Epoch number: 5321 and the loss : 0.36710962653160095\n",
            "Epoch number: 5331 and the loss : 0.36706459522247314\n",
            "Epoch number: 5341 and the loss : 0.36718958616256714\n",
            "Epoch number: 5351 and the loss : 0.3671359121799469\n",
            "Epoch number: 5361 and the loss : 0.3671768009662628\n",
            "Epoch number: 5371 and the loss : 0.36719024181365967\n",
            "Epoch number: 5381 and the loss : 0.3671466112136841\n",
            "Epoch number: 5391 and the loss : 0.3671751916408539\n",
            "Epoch number: 5401 and the loss : 0.3670685589313507\n",
            "Epoch number: 5411 and the loss : 0.36706528067588806\n",
            "Epoch number: 5421 and the loss : 0.36705148220062256\n",
            "Epoch number: 5431 and the loss : 0.3670397698879242\n",
            "Epoch number: 5441 and the loss : 0.3670334219932556\n",
            "Epoch number: 5451 and the loss : 0.367040753364563\n",
            "Epoch number: 5461 and the loss : 0.3670194149017334\n",
            "Epoch number: 5471 and the loss : 0.36700981855392456\n",
            "Epoch number: 5481 and the loss : 0.36699533462524414\n",
            "Epoch number: 5491 and the loss : 0.36704927682876587\n",
            "Epoch number: 5501 and the loss : 0.36700761318206787\n",
            "Epoch number: 5511 and the loss : 0.36703890562057495\n",
            "Epoch number: 5521 and the loss : 0.36698105931282043\n",
            "Epoch number: 5531 and the loss : 0.36697548627853394\n",
            "Epoch number: 5541 and the loss : 0.36700430512428284\n",
            "Epoch number: 5551 and the loss : 0.3669423758983612\n",
            "Epoch number: 5561 and the loss : 0.36701729893684387\n",
            "Epoch number: 5571 and the loss : 0.3669816553592682\n",
            "Epoch number: 5581 and the loss : 0.36701148748397827\n",
            "Epoch number: 5591 and the loss : 0.3670015335083008\n",
            "Epoch number: 5601 and the loss : 0.3669218420982361\n",
            "Epoch number: 5611 and the loss : 0.3669114112854004\n",
            "Epoch number: 5621 and the loss : 0.3668934106826782\n",
            "Epoch number: 5631 and the loss : 0.3669055998325348\n",
            "Epoch number: 5641 and the loss : 0.3671552538871765\n",
            "Epoch number: 5651 and the loss : 0.36708158254623413\n",
            "Epoch number: 5661 and the loss : 0.36684852838516235\n",
            "Epoch number: 5671 and the loss : 0.3668804466724396\n",
            "Epoch number: 5681 and the loss : 0.36681637167930603\n",
            "Epoch number: 5691 and the loss : 0.36688145995140076\n",
            "Epoch number: 5701 and the loss : 0.3668709397315979\n",
            "Epoch number: 5711 and the loss : 0.3671233654022217\n",
            "Epoch number: 5721 and the loss : 0.36682119965553284\n",
            "Epoch number: 5731 and the loss : 0.3670307993888855\n",
            "Epoch number: 5741 and the loss : 0.3670674264431\n",
            "Epoch number: 5751 and the loss : 0.36682361364364624\n",
            "Epoch number: 5761 and the loss : 0.3669130504131317\n",
            "Epoch number: 5771 and the loss : 0.3668854236602783\n",
            "Epoch number: 5781 and the loss : 0.366821825504303\n",
            "Epoch number: 5791 and the loss : 0.3669794797897339\n",
            "Epoch number: 5801 and the loss : 0.3669525980949402\n",
            "Epoch number: 5811 and the loss : 0.367272287607193\n",
            "Epoch number: 5821 and the loss : 0.3668949604034424\n",
            "Epoch number: 5831 and the loss : 0.3669600486755371\n",
            "Epoch number: 5841 and the loss : 0.3668217062950134\n",
            "Epoch number: 5851 and the loss : 0.3667154014110565\n",
            "Epoch number: 5861 and the loss : 0.3669126033782959\n",
            "Epoch number: 5871 and the loss : 0.3667193651199341\n",
            "Epoch number: 5881 and the loss : 0.366702139377594\n",
            "Epoch number: 5891 and the loss : 0.3666560649871826\n",
            "Epoch number: 5901 and the loss : 0.3666742444038391\n",
            "Epoch number: 5911 and the loss : 0.3668403625488281\n",
            "Epoch number: 5921 and the loss : 0.3667161464691162\n",
            "Epoch number: 5931 and the loss : 0.36672458052635193\n",
            "Epoch number: 5941 and the loss : 0.36680299043655396\n",
            "Epoch number: 5951 and the loss : 0.36670392751693726\n",
            "Epoch number: 5961 and the loss : 0.3667139410972595\n",
            "Epoch number: 5971 and the loss : 0.36678561568260193\n",
            "Epoch number: 5981 and the loss : 0.36700403690338135\n",
            "Epoch number: 5991 and the loss : 0.36668047308921814\n",
            "Epoch number: 6001 and the loss : 0.3667322099208832\n",
            "Epoch number: 6011 and the loss : 0.3668076992034912\n",
            "Epoch number: 6021 and the loss : 0.3667651116847992\n",
            "Epoch number: 6031 and the loss : 0.36664557456970215\n",
            "Epoch number: 6041 and the loss : 0.3665522336959839\n",
            "Epoch number: 6051 and the loss : 0.3665689527988434\n",
            "Epoch number: 6061 and the loss : 0.3666234612464905\n",
            "Epoch number: 6071 and the loss : 0.3667164444923401\n",
            "Epoch number: 6081 and the loss : 0.3665717840194702\n",
            "Epoch number: 6091 and the loss : 0.36647406220436096\n",
            "Epoch number: 6101 and the loss : 0.3666008710861206\n",
            "Epoch number: 6111 and the loss : 0.3665086030960083\n",
            "Epoch number: 6121 and the loss : 0.36644676327705383\n",
            "Epoch number: 6131 and the loss : 0.3665960729122162\n",
            "Epoch number: 6141 and the loss : 0.36654844880104065\n",
            "Epoch number: 6151 and the loss : 0.36607006192207336\n",
            "Epoch number: 6161 and the loss : 0.3659926652908325\n",
            "Epoch number: 6171 and the loss : 0.36598166823387146\n",
            "Epoch number: 6181 and the loss : 0.3659966289997101\n",
            "Epoch number: 6191 and the loss : 0.36589282751083374\n",
            "Epoch number: 6201 and the loss : 0.3658645749092102\n",
            "Epoch number: 6211 and the loss : 0.3658914864063263\n",
            "Epoch number: 6221 and the loss : 0.3660019338130951\n",
            "Epoch number: 6231 and the loss : 0.36573007702827454\n",
            "Epoch number: 6241 and the loss : 0.36578667163848877\n",
            "Epoch number: 6251 and the loss : 0.3657911419868469\n",
            "Epoch number: 6261 and the loss : 0.36572039127349854\n",
            "Epoch number: 6271 and the loss : 0.3656880557537079\n",
            "Epoch number: 6281 and the loss : 0.36572927236557007\n",
            "Epoch number: 6291 and the loss : 0.36564207077026367\n",
            "Epoch number: 6301 and the loss : 0.3657843768596649\n",
            "Epoch number: 6311 and the loss : 0.36568212509155273\n",
            "Epoch number: 6321 and the loss : 0.3656676411628723\n",
            "Epoch number: 6331 and the loss : 0.3656899034976959\n",
            "Epoch number: 6341 and the loss : 0.36566558480262756\n",
            "Epoch number: 6351 and the loss : 0.36569467186927795\n",
            "Epoch number: 6361 and the loss : 0.3656432032585144\n",
            "Epoch number: 6371 and the loss : 0.3655632734298706\n",
            "Epoch number: 6381 and the loss : 0.3656418025493622\n",
            "Epoch number: 6391 and the loss : 0.3657270669937134\n",
            "Epoch number: 6401 and the loss : 0.3655882477760315\n",
            "Epoch number: 6411 and the loss : 0.36556053161621094\n",
            "Epoch number: 6421 and the loss : 0.36558017134666443\n",
            "Epoch number: 6431 and the loss : 0.365608811378479\n",
            "Epoch number: 6441 and the loss : 0.36555445194244385\n",
            "Epoch number: 6451 and the loss : 0.36571329832077026\n",
            "Epoch number: 6461 and the loss : 0.36577892303466797\n",
            "Epoch number: 6471 and the loss : 0.36551403999328613\n",
            "Epoch number: 6481 and the loss : 0.3655247390270233\n",
            "Epoch number: 6491 and the loss : 0.365546315908432\n",
            "Epoch number: 6501 and the loss : 0.3654472827911377\n",
            "Epoch number: 6511 and the loss : 0.36555469036102295\n",
            "Epoch number: 6521 and the loss : 0.36551061272621155\n",
            "Epoch number: 6531 and the loss : 0.3654749393463135\n",
            "Epoch number: 6541 and the loss : 0.3655596971511841\n",
            "Epoch number: 6551 and the loss : 0.3654940128326416\n",
            "Epoch number: 6561 and the loss : 0.3653710186481476\n",
            "Epoch number: 6571 and the loss : 0.3656224012374878\n",
            "Epoch number: 6581 and the loss : 0.36528682708740234\n",
            "Epoch number: 6591 and the loss : 0.3653445541858673\n",
            "Epoch number: 6601 and the loss : 0.3655821681022644\n",
            "Epoch number: 6611 and the loss : 0.3653162121772766\n",
            "Epoch number: 6621 and the loss : 0.36535441875457764\n",
            "Epoch number: 6631 and the loss : 0.3653711676597595\n",
            "Epoch number: 6641 and the loss : 0.3653410077095032\n",
            "Epoch number: 6651 and the loss : 0.3652989864349365\n",
            "Epoch number: 6661 and the loss : 0.365378201007843\n",
            "Epoch number: 6671 and the loss : 0.3653397858142853\n",
            "Epoch number: 6681 and the loss : 0.36537566781044006\n",
            "Epoch number: 6691 and the loss : 0.3653515875339508\n",
            "Epoch number: 6701 and the loss : 0.36535322666168213\n",
            "Epoch number: 6711 and the loss : 0.365190327167511\n",
            "Epoch number: 6721 and the loss : 0.36533018946647644\n",
            "Epoch number: 6731 and the loss : 0.36534634232521057\n",
            "Epoch number: 6741 and the loss : 0.3652658462524414\n",
            "Epoch number: 6751 and the loss : 0.3653157353401184\n",
            "Epoch number: 6761 and the loss : 0.365187406539917\n",
            "Epoch number: 6771 and the loss : 0.3654085695743561\n",
            "Epoch number: 6781 and the loss : 0.3651794195175171\n",
            "Epoch number: 6791 and the loss : 0.36523789167404175\n",
            "Epoch number: 6801 and the loss : 0.3652992844581604\n",
            "Epoch number: 6811 and the loss : 0.3651822805404663\n",
            "Epoch number: 6821 and the loss : 0.3652489483356476\n",
            "Epoch number: 6831 and the loss : 0.365200400352478\n",
            "Epoch number: 6841 and the loss : 0.36517733335494995\n",
            "Epoch number: 6851 and the loss : 0.3652263879776001\n",
            "Epoch number: 6861 and the loss : 0.36529213190078735\n",
            "Epoch number: 6871 and the loss : 0.36513036489486694\n",
            "Epoch number: 6881 and the loss : 0.3652268648147583\n",
            "Epoch number: 6891 and the loss : 0.3652483820915222\n",
            "Epoch number: 6901 and the loss : 0.36509913206100464\n",
            "Epoch number: 6911 and the loss : 0.3651973009109497\n",
            "Epoch number: 6921 and the loss : 0.36517205834388733\n",
            "Epoch number: 6931 and the loss : 0.36509713530540466\n",
            "Epoch number: 6941 and the loss : 0.3652207851409912\n",
            "Epoch number: 6951 and the loss : 0.36517471075057983\n",
            "Epoch number: 6961 and the loss : 0.36553969979286194\n",
            "Epoch number: 6971 and the loss : 0.36527398228645325\n",
            "Epoch number: 6981 and the loss : 0.3650681674480438\n",
            "Epoch number: 6991 and the loss : 0.36513665318489075\n",
            "Epoch number: 7001 and the loss : 0.3650387227535248\n",
            "Epoch number: 7011 and the loss : 0.3649713099002838\n",
            "Epoch number: 7021 and the loss : 0.3650510907173157\n",
            "Epoch number: 7031 and the loss : 0.3650228679180145\n",
            "Epoch number: 7041 and the loss : 0.3650011122226715\n",
            "Epoch number: 7051 and the loss : 0.3651377558708191\n",
            "Epoch number: 7061 and the loss : 0.36515745520591736\n",
            "Epoch number: 7071 and the loss : 0.36494529247283936\n",
            "Epoch number: 7081 and the loss : 0.3650648295879364\n",
            "Epoch number: 7091 and the loss : 0.36496585607528687\n",
            "Epoch number: 7101 and the loss : 0.3654266893863678\n",
            "Epoch number: 7111 and the loss : 0.3650366961956024\n",
            "Epoch number: 7121 and the loss : 0.36509838700294495\n",
            "Epoch number: 7131 and the loss : 0.36505845189094543\n",
            "Epoch number: 7141 and the loss : 0.3652278184890747\n",
            "Epoch number: 7151 and the loss : 0.3651255667209625\n",
            "Epoch number: 7161 and the loss : 0.36505642533302307\n",
            "Epoch number: 7171 and the loss : 0.36505126953125\n",
            "Epoch number: 7181 and the loss : 0.36503466963768005\n",
            "Epoch number: 7191 and the loss : 0.3649510443210602\n",
            "Epoch number: 7201 and the loss : 0.36528030037879944\n",
            "Epoch number: 7211 and the loss : 0.36501213908195496\n",
            "Epoch number: 7221 and the loss : 0.36500754952430725\n",
            "Epoch number: 7231 and the loss : 0.36492276191711426\n",
            "Epoch number: 7241 and the loss : 0.3649178743362427\n",
            "Epoch number: 7251 and the loss : 0.36491790413856506\n",
            "Epoch number: 7261 and the loss : 0.36485999822616577\n",
            "Epoch number: 7271 and the loss : 0.3650829493999481\n",
            "Epoch number: 7281 and the loss : 0.364925354719162\n",
            "Epoch number: 7291 and the loss : 0.3648700714111328\n",
            "Epoch number: 7301 and the loss : 0.3649486303329468\n",
            "Epoch number: 7311 and the loss : 0.3650936782360077\n",
            "Epoch number: 7321 and the loss : 0.36499130725860596\n",
            "Epoch number: 7331 and the loss : 0.36490485072135925\n",
            "Epoch number: 7341 and the loss : 0.36491233110427856\n",
            "Epoch number: 7351 and the loss : 0.3648851811885834\n",
            "Epoch number: 7361 and the loss : 0.3648155927658081\n",
            "Epoch number: 7371 and the loss : 0.36496585607528687\n",
            "Epoch number: 7381 and the loss : 0.36484163999557495\n",
            "Epoch number: 7391 and the loss : 0.3648015856742859\n",
            "Epoch number: 7401 and the loss : 0.3649121820926666\n",
            "Epoch number: 7411 and the loss : 0.3651273250579834\n",
            "Epoch number: 7421 and the loss : 0.364970862865448\n",
            "Epoch number: 7431 and the loss : 0.3651181161403656\n",
            "Epoch number: 7441 and the loss : 0.364879846572876\n",
            "Epoch number: 7451 and the loss : 0.3651217520236969\n",
            "Epoch number: 7461 and the loss : 0.3648745119571686\n",
            "Epoch number: 7471 and the loss : 0.3648129403591156\n",
            "Epoch number: 7481 and the loss : 0.3647860288619995\n",
            "Epoch number: 7491 and the loss : 0.3648374080657959\n",
            "Epoch number: 7501 and the loss : 0.3648790717124939\n",
            "Epoch number: 7511 and the loss : 0.36482948064804077\n",
            "Epoch number: 7521 and the loss : 0.36488214135169983\n",
            "Epoch number: 7531 and the loss : 0.3648000657558441\n",
            "Epoch number: 7541 and the loss : 0.36513686180114746\n",
            "Epoch number: 7551 and the loss : 0.36487826704978943\n",
            "Epoch number: 7561 and the loss : 0.3648676872253418\n",
            "Epoch number: 7571 and the loss : 0.36486852169036865\n",
            "Epoch number: 7581 and the loss : 0.36511731147766113\n",
            "Epoch number: 7591 and the loss : 0.3652905523777008\n",
            "Epoch number: 7601 and the loss : 0.3648431599140167\n",
            "Epoch number: 7611 and the loss : 0.36481544375419617\n",
            "Epoch number: 7621 and the loss : 0.3650383949279785\n",
            "Epoch number: 7631 and the loss : 0.36477595567703247\n",
            "Epoch number: 7641 and the loss : 0.3647802770137787\n",
            "Epoch number: 7651 and the loss : 0.3648081421852112\n",
            "Epoch number: 7661 and the loss : 0.3649234473705292\n",
            "Epoch number: 7671 and the loss : 0.3647228181362152\n",
            "Epoch number: 7681 and the loss : 0.36479613184928894\n",
            "Epoch number: 7691 and the loss : 0.36494529247283936\n",
            "Epoch number: 7701 and the loss : 0.3648597300052643\n",
            "Epoch number: 7711 and the loss : 0.3648512065410614\n",
            "Epoch number: 7721 and the loss : 0.36479371786117554\n",
            "Epoch number: 7731 and the loss : 0.3647609055042267\n",
            "Epoch number: 7741 and the loss : 0.36480242013931274\n",
            "Epoch number: 7751 and the loss : 0.3647279441356659\n",
            "Epoch number: 7761 and the loss : 0.3647398352622986\n",
            "Epoch number: 7771 and the loss : 0.3647509813308716\n",
            "Epoch number: 7781 and the loss : 0.36517006158828735\n",
            "Epoch number: 7791 and the loss : 0.36489006876945496\n",
            "Epoch number: 7801 and the loss : 0.3647599518299103\n",
            "Epoch number: 7811 and the loss : 0.36472654342651367\n",
            "Epoch number: 7821 and the loss : 0.3649035096168518\n",
            "Epoch number: 7831 and the loss : 0.36479052901268005\n",
            "Epoch number: 7841 and the loss : 0.3647448718547821\n",
            "Epoch number: 7851 and the loss : 0.36472538113594055\n",
            "Epoch number: 7861 and the loss : 0.3647286891937256\n",
            "Epoch number: 7871 and the loss : 0.36472761631011963\n",
            "Epoch number: 7881 and the loss : 0.3648557662963867\n",
            "Epoch number: 7891 and the loss : 0.3646825850009918\n",
            "Epoch number: 7901 and the loss : 0.3647385835647583\n",
            "Epoch number: 7911 and the loss : 0.36464786529541016\n",
            "Epoch number: 7921 and the loss : 0.3650028109550476\n",
            "Epoch number: 7931 and the loss : 0.3651667535305023\n",
            "Epoch number: 7941 and the loss : 0.3650403916835785\n",
            "Epoch number: 7951 and the loss : 0.36510199308395386\n",
            "Epoch number: 7961 and the loss : 0.36503487825393677\n",
            "Epoch number: 7971 and the loss : 0.3651113212108612\n",
            "Epoch number: 7981 and the loss : 0.36485934257507324\n",
            "Epoch number: 7991 and the loss : 0.3647211492061615\n",
            "12.367055892944336\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "id": "ciYEJJW2fy0B",
        "outputId": "d6405e21-5a57-4f48-c8bd-984361f988b4"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.plot(range(epochs),final_losses)\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')"
      ],
      "execution_count": 309,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Epoch')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 309
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2TYZXHFf8pd",
        "outputId": "85dc9c6c-1b09-4a97-8832-747bb8f13e08"
      },
      "source": [
        "predictions=[]\n",
        "with torch.no_grad():\n",
        "    for i,data in enumerate(X_test):\n",
        "        y_pred=model(data)\n",
        "        predictions.append(y_pred.argmax().item())\n",
        "        print(y_pred.argmax().item())"
      ],
      "execution_count": 310,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "RonSieHMgdYr",
        "outputId": "860012e2-bfe4-4692-be1d-2692c0d32cd2"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm=confusion_matrix(y_test,pred1)\n",
        "cm"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-140-2e612c6d8879>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pred1' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vB3xyffDgi9e",
        "outputId": "81dc78aa-8404-4521-9dd4-fa0ace5d777a"
      },
      "source": [
        "type(predictions)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERADfLfSg2HE",
        "outputId": "8eb79a47-146e-4956-9e3c-7782641d84de"
      },
      "source": [
        "type(y_test)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8ZW9DTPhAfp"
      },
      "source": [
        "y_test1 = y_test.cpu().numpy()"
      ],
      "execution_count": 311,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOMIwMW_hB_4",
        "outputId": "bbae00bc-5fc1-494a-f6cf-0fb3a4b4060a"
      },
      "source": [
        "y_test1"
      ],
      "execution_count": 312,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
              "       1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
              "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
              "       0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "       0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 312
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmKrzf71hDx2"
      },
      "source": [
        "import numpy as np\n",
        "predictions1 = np.array(predictions)"
      ],
      "execution_count": 313,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzXvHJqqhgYh",
        "outputId": "fc96ccd6-6d4e-41ee-e1b6-7308c5a28ad0"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm=confusion_matrix(y_test1,predictions1)\n",
        "cm"
      ],
      "execution_count": 314,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[98,  9],\n",
              "       [18, 29]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 314
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "UtcYwSzkid2v",
        "outputId": "9bb3a749-e0db-4bda-9135-b101ebf0aec4"
      },
      "source": [
        "import seaborn as sns\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.heatmap(cm,annot=True)\n",
        "plt.xlabel('Actual Values')\n",
        "plt.ylabel('Predicted Values')"
      ],
      "execution_count": 315,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(69.0, 0.5, 'Predicted Values')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 315
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAisAAAFzCAYAAAD/m0kvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dedQdZZWo8WeTgGESSMDcMEdBJl2g0MggXgahRUVAaQRtjBiN3EaGBjWoeNW+iNCKiCgXIrmYZTdDZBCaVgTTiDPIpDKo0BGEGBJEBplJvn3/OBX9iPnOOclJnVP11fNj1TpVdeq8teNakO1+d70VmYkkSVJVrTLoACRJktoxWZEkSZVmsiJJkirNZEWSJFWayYokSao0kxVJklRpYwcdwEhe+ONcn6mWBmD1DfcYdAhSYy16fl708369/l276vov70u8lU1WJElSyYYWDzqCrjgNJEmSKs3KiiRJTZVDg46gKyYrkiQ11ZDJiiRJqrCsSWXFnhVJklRpVlYkSWoqp4EkSVKl1WQayGRFkqSmqsk6KyYrkiQ1VU0qKzbYSpKkSrOyIklSU9lgK0mSqqwu66yYrEiS1FRWViRJUqXVpLJig60kSao0KyuSJDWV66xIkqRKq8k0kMmKJElNVZMGW3tWJElSpVlZkSSpqZwGkiRJlVaTaSCTFUmSGirTp4EkSVKV1WQayAZbSZJUaSYrkiQ11dBQb1sHEXFcRNwREXdGxPHFufERcV1E3FN8rtdpHJMVSZKaKod629qIiFcBHwB2BrYH3hoRWwAnAXMyc0tgTnHclj0rkiQ1VbnL7W8D3JiZTwNExA3A24EDgT2La2YB3wemtxvIyookSU3VY2UlIqZFxM3DtmnDRr8D2CMiJkTEGsCbgU2AiZk5v7jmIWBipzCtrEiSpBWSmTOAGSN8d3dEnA5cCzwF3A4sXuqajIjsdB8rK5IkNVXJDbaZOTMzd8zMNwCPAr8FFkTEJIDic2GncUxWJElqqhIbbAEi4mXF56a0+lUuBK4CphSXTAGu7DSO00CSJDVV+cvtXxYRE4AXgKMz87GIOA2YHRFTgfuBQzsNYrIiSZJKkZl7LOPcI8A+yzOOyYokSU3liwwlSVKV+SJDSZJUbVZWJElSpfnWZUmSpN5ZWZEkqamcBpIkSZVWk2kgkxVJkprKyookSaq0mlRWbLCVJEmVZmVFkqSmchpIkiRVmsmKJEmqNHtWJEmSemdlRZKkpnIaSJIkVVpNpoFMViRJaiorK5IkqdJqUlmxwVaSJFWalRVJkprKaSBJklRpJiuSJKnSMgcdQVdMViRJaqqaVFZssJUkSZVmZUWSpKaqSWXFZEWSpKaqyTorJiuSJDVVTSor9qxIkqRSRMQ/R8SdEXFHRFwUEeMiYnJE3BgR90bEJRGxWqdxTFYkSWqqzN62NiJiI+BYYKfMfBUwBjgMOB04MzO3AB4FpnYK02RFkqSmGhrqbetsLLB6RIwF1gDmA3sDlxbfzwIO6mYQSZLURCX2rGTmvIj4AvB74BngWuAW4LHMXFRc9iCwUaexrKxIktRUOdTTFhHTIuLmYdu0JUNHxHrAgcBkYENgTeBNKxKmlRVJkrRCMnMGMGOEr98I/C4zHwaIiMuB3YF1I2JsUV3ZGJjX6T5WViRJaqgcyp62Dn4P7BIRa0REAPsAdwHXA4cU10wBruw0kJUVSZKaqtyelRsj4lLgVmARcButKsx/AhdHxCnFuZmdxjJZkSSpqUpewTYzPwV8aqnTc4Gdl2cckxVJkpqq81ROJdizIkmSKs3KiiRJTVWTdwOZrEiS1FQmK5IkqdI6vN+nKuxZkSRJlWZlRT37xuxvcdlV15CZHPK2N3HEOw/m17/9b/7l82fz3PMvMGbMGD754aN59bZbDTpUadQ65kNTmTr1XUQEM2deyJfPPn/QIakOajINZGVFPbln7n1cdtU1XHT+l7hs1jnc8JOb+P2Df+CMc2byv973bi6b9VU+9P5/5IxzOq75I2kFbbfdVkyd+i523e0tvHbHfXnLm9/IK16x+aDDUh0MZW9bn5SWrETE1hExPSK+XGzTI2Kbsu6nwZh73wO8erutWH3cOMaOHcNOO7ya793wYyKCJ596GoAnn3qal60/YcCRSqPX1ltvyU033cYzzzzL4sWL+cEPf8bBB+0/6LBUBz2+yLBfSklWImI6cDEQwE3FFsBFEXFSGffUYGzx8s249Rd38tjjT/DMs8/yw5/+nIcWPMz04z7IGefMZJ+Dj+ALXzmf449676BDlUatO+/8Na9//esYP349Vl99HPu/aW823njDQYelOqhJZSWyhE7giPgtsF1mvrDU+dWAOzNzyxF+Nw2YBnDOGafs+P73HL7SY9PKd9l/fJdLrria1ceN4xWTN2W1VVdlKJO/2+HV7LvX67lmzg+49KrvcP5Znxt0qOrC6hvuMegQtAKOfO9hHHXUFJ5+6mnuvOu3PPfc85z44aVXOVfVLXp+XvTzfk+ffmRPScAa0y/oS7xlJSu/Bv4+M+9f6vxmwLWZ2bHT8oU/zq3H81R6kS+d+3X+x8vW50vnXsBPv3spEUFmsst+7+DG6y4fdHjqgslK/Z3yf07iwQfnc+55swYdipZTv5OVpz43pae/a9f82Ky+xFtWz8rxwJyI+E5EzCi2a4A5wHEl3VMD8sijjwEw/6GFzLnhx7x53z3ZYP0J/Py2XwFw4y23s9kmGw0yRGnU22CDVl/YJptsyEEH7c9FF18x4IhUCzWZBirl0eXMvCYiXknrrYpL/paaB/w8MxeXcU8Nzj9//BQee+IJxo4dyydO/CdeuvZafGb6sZx21nksWryYl6y2Gp/66LGDDlMa1b55ydcYP2E9XnhhEcce+wkef/yJQYekOuhjk2wvSpkGWhmcBpIGw2kgaXD6Pg10yj/2Ng108r/1JV4XhZMkqan6OJXTC5MVSZKaqiYr2JqsSJLUVFZWJElSpdWkwdZ3A0mSpEqzsiJJUlM5DSRJkqosbbCVJEmVZmVFkiRVWk2SFRtsJUlSpVlZkSSpqWry6LLJiiRJTVWTaSCTFUmSGiprkqzYsyJJkkoREVtFxO3Dtici4viIGB8R10XEPcXneu3GMVmRJKmphrK3rYPM/E1m7pCZOwA7Ak8DVwAnAXMyc0tgTnE8IpMVSZKaamiot2357AP8d2beDxwIzCrOzwIOavdDe1YkSWqqHntWImIaMG3YqRmZOWOEyw8DLir2J2bm/GL/IWBiu/uYrEiS1FQ9JitFYjJScvIXEbEa8DbgY8sYIyOibSBOA0mSpLLtD9yamQuK4wURMQmg+FzY7scmK5IkNVRm9rQth8P56xQQwFXAlGJ/CnBlux87DSRJUlP1YZ2ViFgT2Bf44LDTpwGzI2IqcD9waLsxTFYkSWqqPiQrmfkUMGGpc4/QejqoKyYrkiQ1lCvYSpIkrQRWViRJaqqaVFZMViRJaqrlXoR2MExWJElqKHtWJEmSVgIrK5IkNVVNKismK5IkNZU9K5Ikqcrq0rNisiJJUlPVpLJig60kSao0KyuSJDWU00CSJKnaajINZLIiSVJDpcmKJEmqtJokKx0bbCPiFRHxkmJ/z4g4NiLWLT80SZKk7p4GugxYHBFbADOATYALS41KkiSVLod62/qlm2mgocxcFBEHA2dn5tkRcVvZgUmSpJLVZBqom2TlhYg4HJgCHFCcW7W8kCRJUj/UpcG2m2mgI4Fdgc9m5u8iYjLwjXLDkiRJaulYWcnMuyJiOrBpcfw74PSyA5MkSeUaNZWViDgAuB24pjjeISKuKjswSZJUrro02HYzDfRpYGfgMYDMvB14eYkxSZKkfsjobeuTrhpsM/PxiBcFVZPCkSRJGkldpoG6SVbujIh3AWMiYkvgWOAn5YYlSZLU0s000DHAdsBzwEXAE8DxZQYlSZLKl0PR09Yv3TwN9DTwiWKTJEmjxKiZBoqI64Fc+nxm7l1KRJIkqS+yD02yxfsEzwdeRSufeB/wG+ASYHPgPuDQzHx0pDG66Vn58LD9ccA7gEUrFLEkSaqMPlVWzgKuycxDImI1YA3g48CczDwtIk4CTgKmjzRAN9NAtyx16scRcVMPQUuSpAaIiHWANwDvBcjM54HnI+JAYM/islnA9+klWYmI8cMOVwF2BNZZgZglSVKF9KFJdjLwMHBBRGwP3AIcB0zMzPnFNQ8BE9sN0s000C205piC1vTP74CpKxi0JEmqiPybjtTlExHTgGnDTs3IzBnDjscCrwWOycwbI+IsWlM+w2LIjIi2kXQzDTS5+7AlSVJd9FpZKRKTGW0ueRB4MDNvLI4vpZWsLIiISZk5PyImAQvb3WfEZCUi3t4hwMvbfS9JkpotMx+KiAciYqvM/A2wD3BXsU0BTis+r2w3TrvKygHt7g+YrEiSVGN9WtjtGODfiyeB5gJH0uqBnR0RU4H7gUPbDTBispKZR67EQCVJUsX02rPS3T3ydmCnZXy1T7djdNNgS0S8hdaS++OG3fxfur2JJEmqnn4umd+Lbh5dPpfWAi570VqB7hDAdVYkSaq5fqxguzJ08yLD3TLzPcCjmfkZYFfgleWGJUmS1NLNNNAzxefTEbEh8AgwqbyQJElSP4yaFxkCVxcvIfo8cCutJ4G+VmpUkiSpdEM1mQZqt87Kt4ELgTMz80ngsoi4GhiXmY/3K0BJklSO0dCzch7wFmBuRMyOiINprYproiJJ0iiQQ9HT1i8jJiuZeWVmHg5sDlwGvAf4fURcEBH79ik+SZLUcB2fBsrMpzPzksw8GNgP2AG4pvTIJElSqTJ72/qlm3VWJtJaBvcwWk8BzQbeW25YkiSpbLVfFC4iPgAcDmxFaxroI5n5k34FJkmSylX7p4FoLf72OWBOZl2exJYkSaNNuxcZvq+fgUiSpP6qy6PLXb3IUJIkjT79bJLthcmKJEkNVfuelYgY3+6HmfmnlR+OJEnql9EwDXQLrfcABbAp8Gixvy7we2By6dFJkqTGa7eC7eTMfDnwPeCAzFw/MycAbwWu7VeAkiSpHKNmUThgl8z8wJKDzPxORPxriTEBsN02h5Z9C0nL8I5JfzfoECT1Se17Vob5Q0ScDPxbcfxu4A/lhSRJkvqhLj0rHd8NRGsV2w2AK4DLi/3DywxKkiSVbyijp61fOlZWiqd+jouINTPzqT7EJEmS9BcdKysRsVtE3AXcXRxvHxHnlB6ZJEkqVfa49Us300BnAn8PPAKQmb8A3lBmUJIkqXyjZhoIIDMfiHhRUIvLCUeSJPVLXRpsu0lWHoiI3YCMiFWB4yimhCRJksrWTbJyFHAWsBEwj9aCcP9UZlCSJKl8Q4MOoEvdJCtbZea7h5+IiN2BH5cTkiRJ6oekHtNA3TTYnt3lOUmSVCND2dvWjYi4LyJ+FRG3R8TNxbnxEXFdRNxTfK7Xbox2b13eFdgN2CAiThj21UuBMd2FKEmSqmqof5WVvTLzj8OOTwLmZOZpEXFScTx9pB+3q6ysBqxFK6FZe9j2BHBIr1FLkqTGOhCYVezPAg5qd/GIlZXMvAG4ISK+npn3r7z4JElSFfSpZyWBayMigfMycwYwMTPnF98/BExsN0A3PSvnR8S6Sw4iYr2I+O6KRixJkqphqMctIqZFxM3DtmnLuM3rM/O1wP7A0RHxooVlM7PjgrjdPA20fmY+NmzQRyPiZV38TpIkVVivlZWiSjKjwzXzis+FEXEFsDOwICImZeb8iJgELGw3RjeVlaGI2HTJQURsRn9fCSBJkmooItaMiLWX7AP7AXcAVwFTisumAFe2G6ebysongB9FxA1AAHsAyyrzSJKkGunDonATgSuKV/aMBS7MzGsi4ufA7IiYCtwPHNpukI7JSjHoa4FdilPHL/X4kSRJqqGyk5XMnAtsv4zzjwD7dDtOu3VWts7MXxeJCsAfis9NI2LTzLx1eQKWJEnVUpcVbNtVVk4EPgCcsYzvEti7lIgkSVJfDNUjV2m7zsoHis+9+heOJEnSi7WbBnp7ux9m5uUrPxxJktQvfVxuvyftpoEOKD5fRusdQf9VHO8F/AQwWZEkqcbqsg5Ju2mgIwEi4lpg2yXL4haLt3y9L9FJkqTS9OHR5ZWim3VWNhm2fj/AAmDTkS6WJEn1MBT1nwZaYk7xLqCLiuN3At8rLyRJkqS/6mZRuA9FxMHAkhcPzcjMK8oNS5Ikla32PStLuRX4c2Z+LyLWiIi1M/PPZQYmSZLKVZeelY4vMoyIDwCXAucVpzYCvlVmUJIkqXxD0dvWL928dfloYHfgCYDMvIfW48ySJEml62Ya6LnMfL54YyIRMZb6THNJkqQR1GVRuG4qKzdExMeB1SNiX+CbwH+UG5YkSSpb9rj1SzfJynTgYeBXwAeBbwMnlxmUJEkqX116VtpOA0XEGODOzNwa+Fp/QpIkSf0wKp4GyszFwG8iwhVrJUnSQHTTYLsecGdE3AQ8teRkZr6ttKgkSVLp6vK0TDfJyidLj0KSJPVdP/tOejFishIR44CjgC1oNdfOzMxF/QpMkiSVqy49K+0qK7OAF4AfAvsD2wLH9SMoSZJUvtGQrGybma8GiIiZwE39CUmSJOmv2iUrLyzZycxFS1awlSRJo0PW5K/2dsnK9hHxRLEftFawfaLYz8x8aenRSZKk0tR+Gigzx/QzEEmS1F91SVa6WW5fkiRpYLpZZ0WSJI1Co2lROEmSNArVZVE4p4EkSWqooR63bkTEmIi4LSKuLo4nR8SNEXFvRFwSEat1GsNkRZKkhupHskJrQdm7hx2fDpyZmVsAjwJTOw1gsiJJkkoRERsDbwHOL44D2Bu4tLhkFnBQp3FMViRJaqjscYuIaRFx87Bt2lK3+BLwUf5aiJkAPDbsXYMPAht1itMGW0mSGqrXBtvMnAHMWNZ3EfFWYGFm3hIRe/ZyH5MVSZIaquRF4XYH3hYRbwbGAS8FzgLWjYixRXVlY2Bep4GcBpIkqaF6nQZqO3bmxzJz48zcHDgM+K/MfDdwPXBIcdkU4MpOcZqsSJKkfpoOnBAR99LqYZnZ6QdOA0mS1FBDfVrDNjO/D3y/2J8L7Lw8vzdZkSSpoeryIkOTFUmSGqou7wayZ0WSJFWalRVJkhrKaSBJklRpdXnrssmKJEkN1a+ngXplsiJJUkPVI1WxwVaSJFWclRVJkhrKBltJklRp9qxIkqRKq0eqYrIiSVJj1WUayAZbSZJUaVZWJElqKHtWJElSpdUjVTFZkSSpsexZkSRJWgmsrEiS1FBZk4kgkxVJkhqqLtNAJiuSJDWUTwNJkqRKq0eqYoOtJEmqOCsr6tmpZ/1v9tr39Tzyx0d56xveCcA2r3oln/n8x3jJuNVYtGgxn/no6fzytjsHHKk0ekyYtD5Hn3kc66y/LpnJnAuv5TsXXM1m22zO+089inFrrM7DDy7k7OO+yDNPPjPocFVRdZkGsrKinl1+8X8w9bBjXnTuI//7WL7yha9x4F7v5sunn8dHPnXsgKKTRqfFixfzjVMu4MQ3HsPJB32U/d6zPxttuTEfPP1oLjztG3zk74/jpu/+jAM+ePCgQ1WFDfW49YvJinp2809v4/FHn3jRuSRZa+01AVhr7bVY+NDDgwhNGrUeW/gov7tjLgDPPvUs8+59kPETJzBp8obcfWOrivmrH/6C1+2/6yDDVMVlj//0S9+ngSLiyMy8oN/3VX+d+okzmDn7K0z/9HGsssoqvPPN7xt0SNKotcHGL2Pydi/n3tt/ywP3PMBO+72Om6+9kV3eshsTJq0/6PBUYXV5dHkQlZXPjPRFREyLiJsj4ubHn/X/idfZ4Ucewqmf/CL/c4e3cuonv8ipX/rkoEOSRqWXrDGOE86dzqx/mckzTz7DuR85m/2O2J/PXX0Gq6+5OoteeGHQIUo9K6WyEhG/HOkrYOJIv8vMGcAMgFdusFM9un60TAe/862c8vEvAPCdK7/HZ888ecARSaPPmLFjOPHc6fzoWzdw0zU/A+AP/z2PU4/4NACTJm/Ia/becYARqurKnsqJiHHAD4CX0Mo5Ls3MT0XEZOBiYAJwC3BEZj4/0jhlVVYmAu8BDljG9khJ91SFLHzoYXberfUfyV33+Dvum/vAgCOSRp+j/vVDzLv3Qf7z/Kv+cu6lE9YBICJ4+zH/wHX//t1Bhaca6EOD7XPA3pm5PbAD8KaI2AU4HTgzM7cAHgWmthukrJ6Vq4G1MvP2pb+IiO+XdE8NyBfP+yw7774j641flx/84j/58r/O4OQTTuETn/0wY8eM4bnnnueTJ3x20GFKo8pWO23DG96xF/fffR+nf/tMAC76/L8xafNJ7Pee/QG46Zqf8f3ZcwYZpipuKMutrGRmAk8Wh6sWWwJ7A+8qzs8CPg3835HGiSw50BXlNJA0GK9ZY+NBhyA11iX3fyv6eb8jNnt7T3/XfuP+yzvGGxFjaE31bAF8Ffg88LOiqkJEbAJ8JzNfNdIYProsSVJDZY/b8Adjim3a39wjc3Fm7gBsDOwMbL28cbqCrSRJDdXrCrbDH4zp4trHIuJ6YFdg3YgYm5mLaCUx89r91sqKJEkNVfaicBGxQUSsW+yvDuwL3A1cDxxSXDYFuLLdOFZWJElqqD4sCjcJmFX0rawCzM7MqyPiLuDiiDgFuA2Y2W4QkxVJklSKzPwl8JplnJ9Lq3+lKyYrkiQ1VF3eumyyIklSQ/XzZYS9MFmRJKmh6vIiQ5MVSZIaqqoLwy7NR5clSVKlWVmRJKmhbLCVJEmVZs+KJEmqtLo8DWTPiiRJqjQrK5IkNZQ9K5IkqdLq8uiyyYokSQ1lg60kSao0G2wlSZJWAisrkiQ1lA22kiSp0mywlSRJlVaXyoo9K5IkqdKsrEiS1FB1eRrIZEWSpIYasmdFkiRVWT1SFZMVSZIaywZbSZKklcDKiiRJDVWXyorJiiRJDeWicJIkqdKsrEiSpEqryzorNthKkqRKM1mRJKmhMrOnrZOI2CQiro+IuyLizog4rjg/PiKui4h7is/12o1jsiJJUkMNkT1tXVgEnJiZ2wK7AEdHxLbAScCczNwSmFMcj8hkRZKkhiq7spKZ8zPz1mL/z8DdwEbAgcCs4rJZwEHtxjFZkSRJKyQipkXEzcO2aW2u3Rx4DXAjMDEz5xdfPQRMbHcfnwaSJKmhen10OTNnADM6XRcRawGXAcdn5hMRMXyMjIi2gZisSJLUUP14dDkiVqWVqPx7Zl5enF4QEZMyc35ETAIWthvDaSBJkhpqKLOnrZNolVBmAndn5heHfXUVMKXYnwJc2W4cKyuSJDVUHyoruwNHAL+KiNuLcx8HTgNmR8RU4H7g0HaDmKxIkqRSZOaPgBjh6326HcdkRZKkhupmKqcKTFYkSWqourwbyGRFkqSGsrIiSZIqrS6VFR9dliRJlWZlRZKkhnIaSJIkVVpdpoFMViRJaqjMoUGH0BV7ViRJUqVZWZEkqaF6fetyv5isSJLUUGmDrSRJqjIrK5IkqdLqUlmxwVaSJFWalRVJkhrKReEkSVKluSicJEmqtLr0rJisSJLUUHV5GsgGW0mSVGlWViRJaiingSRJUqX5NJAkSaq0ulRW7FmRJEmVZmVFkqSGqsvTQCYrkiQ1VF2mgUxWJElqKBtsJUlSpdVluX0bbCVJUqWZrEiS1FBDmT1tnUTE/4uIhRFxx7Bz4yPiuoi4p/hcr9M4JiuSJDVUZva0deHrwJuWOncSMCcztwTmFMdtmaxIktRQ2eM/HcfP/AHwp6VOHwjMKvZnAQd1GscGW0mSGqrXR5cjYhowbdipGZk5o8PPJmbm/GL/IWBip/uYrEiSpBVSJCadkpN2v8+I6JgxmaxIktRQA1oUbkFETMrM+RExCVjY6Qf2rEiS1FDZ47aCrgKmFPtTgCs7/SDqstSu6iUipnUxbylpJfPfPVVJRFwE7AmsDywAPgV8C5gNbArcDxyamUs34b54HJMVlSEibs7MnQYdh9Q0/run0chpIEmSVGkmK5IkqdJMVlQW58ylwfDfPY069qxIkqRKs7IiSZIqzWRFK1VEvCkifhMR90ZEx5dTSVo5lvV2W2m0MFnRShMRY4CvAvsD2wKHR8S2g41Kaoyv87dvt5VGBZMVrUw7A/dm5tzMfB64mNbbNSWVbIS320qjgsmKVqaNgAeGHT9YnJMkaYWZrEiSpEozWdHKNA/YZNjxxsU5SZJWmMmKVqafA1tGxOSIWA04jNbbNSVJWmEmK1ppMnMR8CHgu8DdwOzMvHOwUUnNULzd9qfAVhHxYERMHXRM0sriCraSJKnSrKxIkqRKM1mRJEmVZrIiSZIqzWRFkiRVmsmKJEmqNJMVqYIi4qCIyIjYuotrj4+INXq413sj4itLndu8ePx1laXO3x4RrxthnM1946+kMpisSNV0OPCj4rOT44EVTlaWJTPvA34P7LHkXJE4rZ2ZN67Me0lSJyYrUsVExFrA64GptFYBXnJ+TER8ISLuiIhfRsQxEXEssCFwfURcX1z35LDfHBIRXy/2D4iIGyPitoj4XkRM7BDKRcPvX+xfXFRQfhgRtxbbbsv4M7yoWhMRV0fEnsX+fhHx0+K33yz+vETEaRFxV/Fn+8Jy/E8maZQbO+gAJP2NA4FrMvO3EfFIROyYmbcA04DNgR0yc1FEjM/MP0XECcBemfnHDuP+CNglMzMi3g98FDixzfWzgdsj4phideJ3Av8ALAT2zcxnI2JLWknNTt38wSJifeBk4I2Z+VRETAdOiIivAgcDWxfxrdvNeJKawWRFqp7DgbOK/YuL41uANwLnFokDmfmn5Rx3Y+CSiJgErAb8rt3Fmbmg6EHZJyIWAIsy846IWAf4SkTsACwGXrkcMewCbAv8OCIo4vgp8DjwLDAzIq4Grl6+P5qk0cxkRaqQiBgP7A28OiISGANkRHxkOYYZ/g6NccP2zwa+mJlXFVMyn+5irCVTQQuKfYB/Lo63pzWV/OwyfreIF08zL4kjgOsy8296cSJiZ2Af4BBa75jau4v4JDWAPStStRwCfCMzN8vMzTNzE1oVkD2A64APRsRY+EtiA/BnYO1hYyyIiG2KJ3kOHnZ+HWX3dRsAAAD1SURBVGBesT+ly3guB95Mawro4mHjzM/MIeAIWgnV0u4DdoiIVSJiE2Dn4vzPgN0jYoviz7BmRLyy6FtZJzO/TSsZ2r7L+CQ1gMmKVC2HA1csde6y4vz5tJ7Q+WVE/AJ4V/H9DOCaJQ22wEm0plF+AswfNs6ngW9GxC1Ap/4WADLzMVrTNAsyc25x+hxgShHD1sBTy/jpj2klWXcBXwZuLcZ7GHgvcFFE/LIYe2taydbVxbkfASd0E5+kZvCty5IkqdKsrEiSpEozWZEkSZVmsiJJkirNZEWSJFWayYokSao0kxVJklRpJiuSJKnSTFYkSVKl/X9P5V87j3SiqwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DuWUPT-bihjn",
        "outputId": "276a0810-4a59-4f15-d806-d2474565d898"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "score=accuracy_score(y_test1,predictions1)\n",
        "score"
      ],
      "execution_count": 316,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8246753246753247"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 316
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAuE2gjXisT6"
      },
      "source": [
        "x = torch.ones(5)  # input tensor\n",
        "y = torch.zeros(3)  # expected output\n",
        "w = torch.randn(5, 3, requires_grad=True)\n",
        "b = torch.randn(3, requires_grad=True)\n",
        "z = torch.matmul(x, w)+b\n",
        "loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eb4XTB1Dn_rP",
        "outputId": "712d5292-eeff-4f3e-cd17-5be34b58d000"
      },
      "source": [
        "loss"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.9706, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xq5caut9oAcH",
        "outputId": "66284088-1de0-44eb-8da4-8f631e2e3bbb"
      },
      "source": [
        "z"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.3567,  2.2005, -2.5459], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Is39FwbsoCLj",
        "outputId": "313858d9-8801-448d-935d-99b18d5be1a0"
      },
      "source": [
        "w.shape"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KBXBWDpoJmB",
        "outputId": "cb904b39-bb43-412b-f611-4fd418cf8c0f"
      },
      "source": [
        "print('Gradient function for z =',z.grad_fn)\n",
        "print('Gradient function for loss =', loss.grad_fn)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gradient function for z = <AddBackward0 object at 0x7fac71593810>\n",
            "Gradient function for loss = <BinaryCrossEntropyWithLogitsBackward object at 0x7fac71593b10>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgAb_JgxoSUO",
        "outputId": "4525b892-7e2c-483a-8a81-8380e7b30b56"
      },
      "source": [
        "loss.backward()\n",
        "print(w.grad)\n",
        "print(b.grad)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.1373, 0.3001, 0.0242],\n",
            "        [0.1373, 0.3001, 0.0242],\n",
            "        [0.1373, 0.3001, 0.0242],\n",
            "        [0.1373, 0.3001, 0.0242],\n",
            "        [0.1373, 0.3001, 0.0242]])\n",
            "tensor([0.1373, 0.3001, 0.0242])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZjqOhqYoV4r",
        "outputId": "829a25c8-6e5c-4da4-9816-f84cd039f019"
      },
      "source": [
        "w"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1454,  1.8462, -0.3794],\n",
              "        [-0.3309,  0.1217, -1.7563],\n",
              "        [ 0.3290,  0.0075, -0.9869],\n",
              "        [-2.1235, -0.5774, -0.7646],\n",
              "        [ 1.0021,  0.1666,  1.0439]], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fa09nVNToXxS",
        "outputId": "9f7a5204-4047-4f5b-b0e2-a36d396e7a10"
      },
      "source": [
        "b"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.9120, 0.6360, 0.2973], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nBUj2vToZ6l"
      },
      "source": [
        "m = nn.Dropout(p=0.2)\n",
        "input = torch.randn(20, 16)\n",
        "output = m(input)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q48a25L8ppY-",
        "outputId": "80e9afa4-5e1e-499a-d5ee-4aea1c640526"
      },
      "source": [
        "output.shape"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([20, 16])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJD6epBApqXf",
        "outputId": "b4835af8-0bbf-4268-d281-85715a1ac3ad"
      },
      "source": [
        "input.shape"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([20, 16])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTv8S0uLpt_8",
        "outputId": "1681dc8d-d37c-44bd-b91f-ded8bf44b09f"
      },
      "source": [
        "input.size()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([20, 16])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haj217Uzpxwg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}